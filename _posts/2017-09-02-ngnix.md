---
layout: post
title: 'ngnix入门'
subtitle: 'nginx特性与配置以及使用场景'
date: 2017-09-02
categories: 服务器性能
author: yates
cover: 'http://cctv.com'
tags: ngnix
---
### 前言
nginx作为当下流行的服务器搭建必不可少的一门技术，在各种应用场景中对服务器性能提升能起到明显的效果。本文只针对nginx在不配合第三方模块所能够处理的一些问题进行描述，文中有不足之处，还望指出

## ngnix能做什么

* 负载均衡
* 反向代理
* 动静分离
* 正向代理


首先解释**代理**的概念，就是你不能直接访问为你提供服务的那台服务器，需要有个中间人来帮你转达你的请求，或者服务器返回的信息。 

**正向代理** 
举个栗子，我们国家因为某些原因无法访问国外youtube，google这些网站，那么你就需要找个服务，来让你能迂回的访问到youtube，google的服务器。这种服务对你来说就是正向代理。参考各种翻墙软件。 

**反向代理** 
再举个栗子，我们访问某个网站的服务,这个服务后面真正**处理你的请求的服务器**和你**进行交互的服务器**是**不一样**的，但是你并不需要关心谁在真正处理服务，只需通过**交互服务器**来获取数据，这个过程中的 **交互服务器** 就是反向代理了。而你在这个过程中是完全无感的。

### 负载均衡

目前市面上最常见的负载均衡技术方案有三种

- 基于DNS负载均衡 当用户访问域名的时候，先向DNS服务器解析域名对应的IP，通过在dns服务器上配置让DNS服务器根据不同地理位置的用户返回不同IP
- 基于硬件负载均衡 比较出名的就是F5 network big-ip，作为一个网络设备每秒处理请求数达百万级，但是价格不菲
- 基于软件的负载均衡 通过软件方式来分发和均衡流量，分为4层和7层协议，基于4层负载性能要高一些，一般几十万/秒处理量，而基于7层负载处理能力一般在几万/秒

### nginx的负载均衡策略
1. 轮询（默认）
每个web请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
2. 最少链接
web请求会被转发到连接数最少的服务器上。
least_conn;
3. weight 权重
指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况，weight默认是1。
server 127.0.0.1:8081 weight=2; #服务器A
4. ip_hash
每个请求按访问ip的hash值分配，这样同一客户端连续的Web请求都会被分发到同一服务器进行处理，可以解决session的问题。当后台服务器宕机时，会自动跳转到其它服务器。
基于weight的负载均衡和基于ip_hash的负载均衡可以组合在一起使用。
5. url_hash（第三方）
url_hash是nginx的第三方模块，nginx本身不支持，需要打补丁。
nginx按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存服务器、文件服务器、静态服务器时比较有效。缺点是当后端服务器宕机的时候，url_hash不会自动跳转的其他缓存服务器，而是返回给用户一个503错误。
6. fair（第三方）
按后端服务器的响应时间来分配请求，响应时间短的优先分配。

>一份比较全的ngnix配置文档如下：
```
#定义Nginx运行的用户和用户组
user www www;
 
#nginx进程数，建议设置为等于CPU总核心数。
worker_processes 8;
 
#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]
error_log /var/log/nginx/error.log info;
 
#进程文件
pid /var/run/nginx.pid;
 
#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。
worker_rlimit_nofile 65535;
 
#工作模式与连接数上限
events
{
#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。
use epoll;
#单个进程最大连接数（最大连接数=连接数*进程数）
worker_connections 65535;
}
 
#设定http服务器
http
{
include mime.types; #文件扩展名与文件类型映射表
default_type application/octet-stream; #默认文件类型
#charset utf-8; #默认编码
server_names_hash_bucket_size 128; #服务器名字的hash表大小
client_header_buffer_size 32k; #上传文件大小限制
large_client_header_buffers 4 64k; #设定请求缓
client_max_body_size 8m; #设定请求缓
sendfile on; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。
autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。
tcp_nopush on; #防止网络阻塞
tcp_nodelay on; #防止网络阻塞
keepalive_timeout 120; #长连接超时时间，单位是秒
 
#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。
fastcgi_connect_timeout 300;
fastcgi_send_timeout 300;
fastcgi_read_timeout 300;
fastcgi_buffer_size 64k;
fastcgi_buffers 4 64k;
fastcgi_busy_buffers_size 128k;
fastcgi_temp_file_write_size 128k;
 
#gzip模块设置
gzip on; #开启gzip压缩输出
gzip_min_length 1k; #最小压缩文件大小
gzip_buffers 4 16k; #压缩缓冲区
gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）
gzip_comp_level 2; #压缩等级
gzip_types text/plain application/x-javascript text/css application/xml;
#压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。
gzip_vary on;
#limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用
 
upstream blog.ha97.com {
#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。
server 192.168.80.121:80 weight=3;
server 192.168.80.122:80 weight=2;
server 192.168.80.123:80 weight=3;
}
 
#虚拟主机的配置
server
{
    #监听端口
    listen 80;
    #域名可以有多个，用空格隔开
    server_name www.ha97.com ha97.com;
    index index.html index.htm index.php;
    root /data/www/ha97;
    location ~ .*\.(php|php5)?$
    {
    fastcgi_pass 127.0.0.1:9000;
    fastcgi_index index.php;
    include fastcgi.conf;
    }
    #图片缓存时间设置
    location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$
    {
    expires 10d;
    }
    #JS和CSS缓存时间设置
    location ~ .*\.(js|css)?$
    {
    expires 1h;
    }
    #日志格式设定
    log_format access '$remote_addr - $remote_user [$time_local] "$request" '
    '$status $body_bytes_sent "$http_referer" '
    '"$http_user_agent" $http_x_forwarded_for';
    #定义本虚拟主机的访问日志
    access_log /var/log/nginx/ha97access.log access;
 
    #对 "/" 启用反向代理
    location / {
    proxy_pass http://127.0.0.1:88;
    proxy_redirect off;
    proxy_set_header X-Real-IP $remote_addr;
    #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    #以下是一些反向代理的配置，可选。
    proxy_set_header Host $host;
    client_max_body_size 10m; #允许客户端请求的最大单文件字节数
    client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数，
    proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时)
    proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时)
    proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时)
    proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小
    proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置
    proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2）
    proxy_temp_file_write_size 64k;
    #设定缓存文件夹大小，大于这个值，将从upstream服务器传
    }
 
    #设定查看Nginx状态的地址
    location /NginxStatus {
    stub_status on;
    access_log on;
    auth_basic "NginxStatus";
    auth_basic_user_file conf/htpasswd;
    #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。
    } 
 
    #本地动静分离反向代理配置
    #所有jsp的页面均交由tomcat或resin处理
    location ~ .(jsp|jspx|do)?$ {
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_pass http://127.0.0.1:8080;
    }
    #所有静态文件由nginx直接读取不经过tomcat或resin
    location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$
    { expires 15d; }
    location ~ .*.(js|css)?$
    { expires 1h; }
}
}
```

nginx 有一个**主进程**和**若干工作进程**，主进程用于读取配置文件，工作进程负责处理请求。，我们要停止nginx服务只需要正常关闭主进程就行了

**nginx配置文件**
所在目录，/usr/local/nginx/conf,/etc/ngnix或 /usr/local/etc/ngnix;配置文件中由指令（简单指令：名称，参数之间用空格分隔，并以分号结尾构成；块指令：使用一组{}包括起来的简单指令）构成

**提供静态内容**
通过在http模块中配置不同的**server模块**，不同模块通过不同侦听的**端口和服务器名称**区分。当请求到达时，nginx根据块参数来分发请求。在server模块中配置**location**模块，location块默认指定"/"前缀，多个location模块时，nginx将选择前缀最长的块。不同URL开头的请求将定位到不同location资源返回。

**nginx基本控制指令**
nginx -s stop 快速停止Nginx服务
nginx -s quit 优雅停止Nginx服务。等待工作进程完成当前请求
nginx -s reload 重载Nginx配置服务。一旦主进程接收到重载配置文件的信号，先验证配置文件语法，然后应用配置文件，成功后创建新的工作进程并发送信号给旧的工作进程进行quit操作
nginx -s reopen 打开日志文件

ps -ax | grep nginx 查看运行的Nginx进程

**负载均衡**

1. http流量负载均衡
要想分发HTTP流量，首先需要在nginx配置文件上下文中定义一个后端upstream组，如下：
```java
http {
    upstream backend {
        server backend1.example.com weight=5;
        server backend2.example.com;
        server 192.0.0.1 backup;
    }
}
```
然后在server模块下进行location代理配置指向上面建立的组
```java
server {
    location / {
        proxy_pass http://backend;
    }
}
```

- 负载策略
    - Round Robin：在考虑服务器**权重**的情况下，在服务器之间使用轮询的方式进行请求分发（nginx默认使用此策略）
    - Least connections：在考虑服务器**权重**的情况下，分发请求到当前最少连接的服务器
    - IP Hash：通过对客户端ip进行hash处理（通常使用IPV4地址前三个八位位组或整个IPV6地址计算哈希值），将其转发到对于服务器，除非该服务器**不可用**
    - Generic hash：根据**用户定义的键**确定分发服务器。该键可以是文本字符串，变量或组合。
    - Least Time：根据**平均最短响应时间和最少活跃连接数**的服务器，最低延迟计算规则（header：从服务器接收第一个字节时间；last_type：从服务器接收完整响应时间；last_type inflight：在 last_type基础上，考虑响应消息**传送的时间**）
    - Random：随机分发请求。同时可配置特殊规则：1-least_conn，2-least_time=header，3-least_time=last_byte。首先，考虑服务器权重选择两个服务器，然后使用特殊规则选择其中一个服务器分发请求
    
上述负载策略配置方式
```java
upstream backend {
    least_conn;// least_conn//ip_hash//hash $request_uri consistent;//least_time header//least_time last_byte//least_time last_byte inflight// random two least_time=last_byte;
    server backend1.example.com;
    server backend2.example.com;
}
```

- 服务器权重
nginx默认服务器权重为1，服务器权重配置如下：
```java
upstream backend {
    server backend1.example.com weight=5;
    server backend2.example.com;
}
```
例：此时有6个请求到达，那么有5个请求会分发到backend1，剩下一个分发到backend2.

- 备用的服务器
备用服务器在有其他服务器不可用情况下会启用，配置如下：
```java
upstream backend {
    server backend1.example.com;
    server backend2.example.com;
    server 192.0.0.1 backup;
}
```

- 服务器慢启动
服务器慢启动为了保护最近恢复的服务器，不会因为大量的连接请求而导致再次被故障。慢启动使用**0**作为最近恢复的服务器权重，随后再渐渐恢复到正常值。配置如下：
```java
upstream backend {
    server backend1.example.com slow_start=30s;
    server backend2.example.com;
    server 192.0.0.1 backup;
}
```
backend1服务器在启动后会在30s内，渐渐恢复到最大连接数的状态

**注意**：在一个upstream组中如果只有一个服务器，那么max_fails，fail_timeout和slow_start参数会失效

- 会话持久性
nginx定义用户请求session并把具有相同session的请求转发到相同的upstream服务器

    - Stickey cookie：nginx添加cookie到upstream组中对首次请求进行响应的服务器，客户端下次请求会直接路由到该服务器。配置如下：
    ```java
    upstream backend {
    server backend1.example.com;
    server backend2.example.com;
    sticky cookie srv_id expires=1h domain=.example.com path=/;
}
```
    - Sticky route:为第一次收到的请求客户端指定一个**路由**，所有子请求，带有路由标识的都会直接分发到该服务器，路由标识由cookie或请求url携带，配置如下：
    ```java
    upstream backend {
    server backend1.example.com route=a;
    server backend2.example.com route=b;
    sticky route $route_cookie $route_uri;
    }
    ```
    - Sticky learn:nginx通过检查请求和响应来查找会话，并从中匹配符合会话的服务器，会话标识通常置于HTTP cookie中，而**不存在于客户端**中。配置如下：
    ```java
    upstream backend {
   server backend1.example.com;
   server backend2.example.com;
   sticky learn
       create=$upstream_cookie_examplecookie
       lookup=$cookie_examplecookie
       zone=client_sessions:1m
       timeout=1h;
       sysnc;//如果有多个nginx实例使用该持久方式时且需要同步共享内存区域
    }
    ```
        上述例子中，必填参数**create**指定创建的会话标识符examplecookie，必填参数**lokup**指定如何查找会话标识符，必填参数**zone**标识携带该会话标识符的会话**共享的内存区域**，这种复杂的配置将coolie保存在服务器共享区域中，而不是客户端.

- 限制连接数量，配置如下:
    ```java
    upstream backend {
        server backend1.example.com max_conns=3;
        server backend2.example.com;
        queue 100 timeout=70;
    }
    ```
    如果max_conns达最大限制，可以设置queue来进一步处理（队列中最大存在的请求数，以及请求超时时间）
- nginx工作进程共享区域
如果一个upstream组**没有配置zone指令**，每一个工作进程都会拥有独立的一份**服务器组配置副本**和一个计数器（包括组中每个服务器当前**连接数**以及请求**分发失败次数**）。这样带来的问题是没法动态修改服务器组配置。每个请求仅到达一个工作进程，当该工作进程**无法将请求分发**时，**其他进程一无所知**，而其他工作进程仍可能向该服务发送请求。同样，在**低负载**情况下，如果使用least connections负载策略，每个进程都会以自己副本中连接数作为标准进行请求分发（有可能该服务器才响应一个请求）。zone指令对于活跃检查和动态配置是必填参数。
    - zone区域大小设置在不同使用模式下差异很大，取决于启用的功能（会话持久性，活跃检查，DNS解析）,在sticky_route的持久方式和单个活跃检查情况下，256KB的设置可保存消息如下：
        - 123个服务器（IP地址：端口对）
        - 88个服务器（主机名：端口对，主机名解析为**单个IP地址**）
        - 12个服务器（主机名：端口对，其中主机名解析为**多个IP地址**）
        
- DNS负载HTTP请求
通过在server指令下定义代理路由指向upstream组，nginx监听dns列表的变化并自动应用更新，配置如下：
    ```java
    http {
        resolver 10.0.0.1 valid=300s ipv6=off;// DNS服务器地址，以及重新解析频率，适用解析IP规则
        resolver_timeout 10s;
        server {
            location / {
                proxy_pass http://backend;
            }
        }
        upstream backend {
            zone backend 32k;
            least_conn;
            # ...
            server backend1.example.com resolve;
            server backend2.example.com resolve;
        }
    }
    ```