---
layout: post
title: 'ngnix入门'
subtitle: 'nginx特性与配置以及使用场景'
date: 2017-09-02
categories: 服务器性能
author: yates
cover: 'http://cctv.com'
tags: ngnix
---
### 前言
nginx作为当下流行的服务器搭建必不可少的一门技术，在各种应用场景中对服务器性能提升能起到明显的效果。本文只针对nginx在不配合第三方模块所能够处理的一些问题进行描述，文中有不足之处，还望指出

## ngnix能做什么

* 负载均衡
* 反向代理
* 动静分离
* 正向代理


首先解释**代理**的概念，就是你不能直接访问为你提供服务的那台服务器，需要有个中间人来帮你转达你的请求，或者服务器返回的信息。 

**正向代理** 
举个栗子，我们国家因为某些原因无法访问国外youtube，google这些网站，那么你就需要找个服务，来让你能迂回的访问到youtube，google的服务器。这种服务对你来说就是正向代理。参考各种翻墙软件。 

**反向代理** 
再举个栗子，我们访问某个网站的服务,这个服务后面真正**处理你的请求的服务器**和你**进行交互的服务器**是**不一样**的，但是你并不需要关心谁在真正处理服务，只需通过**交互服务器**来获取数据，这个过程中的 **交互服务器** 就是反向代理了。而你在这个过程中是完全无感的。

### 负载均衡

目前市面上最常见的负载均衡技术方案有三种

- 基于DNS负载均衡 当用户访问域名的时候，先向DNS服务器解析域名对应的IP，通过在dns服务器上配置让DNS服务器根据不同地理位置的用户返回不同IP
- 基于硬件负载均衡 比较出名的就是F5 network big-ip，作为一个网络设备每秒处理请求数达百万级，但是价格不菲
- 基于软件的负载均衡 通过软件方式来分发和均衡流量，分为4层和7层协议，基于4层负载性能要高一些，一般几十万/秒处理量，而基于7层负载处理能力一般在几万/秒

### nginx的负载均衡策略
1. 轮询（默认）
每个web请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
2. 最少链接
web请求会被转发到连接数最少的服务器上。
least_conn;
3. weight 权重
指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况，weight默认是1。
server 127.0.0.1:8081 weight=2; #服务器A
4. ip_hash
每个请求按访问ip的hash值分配，这样同一客户端连续的Web请求都会被分发到同一服务器进行处理，可以解决session的问题。当后台服务器宕机时，会自动跳转到其它服务器。
基于weight的负载均衡和基于ip_hash的负载均衡可以组合在一起使用。
5. url_hash（第三方）
url_hash是nginx的第三方模块，nginx本身不支持，需要打补丁。
nginx按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存服务器、文件服务器、静态服务器时比较有效。缺点是当后端服务器宕机的时候，url_hash不会自动跳转的其他缓存服务器，而是返回给用户一个503错误。
6. fair（第三方）
按后端服务器的响应时间来分配请求，响应时间短的优先分配。

>一份比较全的ngnix配置文档如下：
```
#定义Nginx运行的用户和用户组
user www www;
 
#nginx进程数，建议设置为等于CPU总核心数。
worker_processes 8;
 
#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]
error_log /var/log/nginx/error.log info;
 
#进程文件
pid /var/run/nginx.pid;
 
#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数
（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，
所以建议与ulimit -n的值保持一致。
worker_rlimit_nofile 65535;
 
#工作模式与连接数上限
events
{
#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; 
epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，
如果跑在FreeBSD上面，就用kqueue模型。
use epoll;
#单个进程最大连接数（最大连接数=连接数*进程数）
worker_connections 65535;
}
 
#设定http服务器
http
{
include mime.types; #文件扩展名与文件类型映射表
default_type application/octet-stream; #默认文件类型
#charset utf-8; #默认编码
server_names_hash_bucket_size 128; #服务器名字的hash表大小
client_header_buffer_size 32k; #上传文件大小限制
large_client_header_buffers 4 64k; #设定请求缓
client_max_body_size 8m; #设定请求缓
sendfile on; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，
对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，
以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。
autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。
tcp_nopush on; #防止网络阻塞
tcp_nodelay on; #防止网络阻塞
keepalive_timeout 120; #长连接超时时间，单位是秒
 
#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。
下面参数看字面意思都能理解。
fastcgi_connect_timeout 300;
fastcgi_send_timeout 300;
fastcgi_read_timeout 300;
fastcgi_buffer_size 64k;
fastcgi_buffers 4 64k;
fastcgi_busy_buffers_size 128k;
fastcgi_temp_file_write_size 128k;
 
#gzip模块设置
gzip on; #开启gzip压缩输出
gzip_min_length 1k; #最小压缩文件大小
gzip_buffers 4 16k; #压缩缓冲区
gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）
gzip_comp_level 2; #压缩等级
gzip_types text/plain application/x-javascript text/css application/xml;
#压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，
但是会有一个warn。
gzip_vary on;
#limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用
 
upstream blog.ha97.com {
#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。
weigth参数表示权值，权值越高被分配到的几率越大。
server 192.168.80.121:80 weight=3;
server 192.168.80.122:80 weight=2;
server 192.168.80.123:80 weight=3;
}
 
#虚拟主机的配置
server
{
    #监听端口
    listen 80;
    #域名可以有多个，用空格隔开
    server_name www.ha97.com ha97.com;
    index index.html index.htm index.php;
    root /data/www/ha97;
    location ~ .*\.(php|php5)?$
    {
    fastcgi_pass 127.0.0.1:9000;
    fastcgi_index index.php;
    include fastcgi.conf;
    }
    #图片缓存时间设置
    location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$
    {
    expires 10d;
    }
    #JS和CSS缓存时间设置
    location ~ .*\.(js|css)?$
    {
    expires 1h;
    }
    #日志格式设定
    log_format access '$remote_addr - $remote_user [$time_local] "$request" '
    '$status $body_bytes_sent "$http_referer" '
    '"$http_user_agent" $http_x_forwarded_for';
    #定义本虚拟主机的访问日志
    access_log /var/log/nginx/ha97access.log access;
 
    #对 "/" 启用反向代理
    location / {
    proxy_pass http://127.0.0.1:88;
    proxy_redirect off;
    proxy_set_header X-Real-IP $remote_addr;
    #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    #以下是一些反向代理的配置，可选。
    proxy_set_header Host $host;
    client_max_body_size 10m; #允许客户端请求的最大单文件字节数
    client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数，
    proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时)
    proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时)
    proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时)
    proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小
    proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置
    proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2）
    proxy_temp_file_write_size 64k;
    #设定缓存文件夹大小，大于这个值，将从upstream服务器传
    }
 
    #设定查看Nginx状态的地址
    location /NginxStatus {
    stub_status on;
    access_log on;
    auth_basic "NginxStatus";
    auth_basic_user_file conf/htpasswd;
    #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。
    } 
 
    #本地动静分离反向代理配置
    #所有jsp的页面均交由tomcat或resin处理
    location ~ .(jsp|jspx|do)?$ {
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_pass http://127.0.0.1:8080;
    }
    #所有静态文件由nginx直接读取不经过tomcat或resin
    location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$
    { expires 15d; }
    location ~ .*.(js|css)?$
    { expires 1h; }
}
}
```

nginx 有一个**主进程**和**若干工作进程**，主进程用于读取配置文件，工作进程负责处理请求。，我们要停止nginx服务只需要正常关闭主进程就行了

**nginx配置文件**
所在目录，/usr/local/nginx/conf,/etc/ngnix或 /usr/local/etc/ngnix;配置文件中由指令（简单指令：名称，参数之间用空格分隔，并以分号结尾构成；块指令：使用一组{}包括起来的简单指令）构成

**提供静态内容**
通过在http模块中配置不同的**server模块**，不同模块通过不同侦听的**端口和服务器名称**区分。当请求到达时，nginx根据块参数来分发请求。在server模块中配置**location**模块，location块默认指定"/"前缀，多个location模块时，nginx将选择前缀最长的块。不同URL开头的请求将定位到不同location资源返回。

**nginx基本控制指令**

- nginx -s stop 快速停止Nginx服务
- nginx -s quit 优雅停止Nginx服务。等待工作进程完成当前请求
- nginx -s reload 重载Nginx配置服务。一旦主进程接收到重载配置文件的信号，先验证配置文件语法，然后应用配置文件，成功后创建新的工作进程并发送信号给旧的工作进程进行quit操作
- nginx -s reopen 打开日志文件
- ps -ax | grep nginx 查看运行的Nginx进程

### 负载均衡

#### **http流量负载均衡**
要想分发HTTP流量，首先需要在nginx配置文件上下文中定义一个后端upstream组，如下：
```java
http {
    upstream backend {
        server backend1.example.com weight=5;
        server backend2.example.com;
        server 192.0.0.1 backup;
    }
}
```
然后在server模块下进行location代理配置指向上面建立的组
```java
server {
    location / {
        proxy_pass http://backend;
    }
}
```

- 负载策略
    - Round Robin：在考虑服务器**权重**的情况下，在服务器之间使用轮询的方式进行请求分发（nginx默认使用此策略）
    - Least connections：在考虑服务器**权重**的情况下，分发请求到当前最少连接的服务器
    - IP Hash：通过对客户端ip进行hash处理（通常使用IPV4地址前三个八位位组或整个IPV6地址计算哈希值），将其转发到对于服务器，除非该服务器**不可用**
    - Generic hash：根据**用户定义的键**确定分发服务器。该键可以是文本字符串，变量或组合。
    - Least Time：根据**平均最短响应时间和最少活跃连接数**的服务器，最低延迟计算规则（
		- header：从服务器接收第一个字节时间；
		- last_type：从服务器接收完整响应时间；
		- last_type inflight：在 last_type基础上，考虑响应消息**传送的时间**
    - Random：随机分发请求。同时可配置特殊规则：1-least_conn，2-least_time=header，3-least_time=last_byte。首先，考虑服务器权重选择两个服务器，然后使用特殊规则选择其中一个服务器分发请求
    
上述负载策略配置方式
```java
upstream backend {
    least_conn;// least_conn//ip_hash//hash $request_uri consistent;//least_time header//least_time last_byte//least_time last_byte inflight// random two least_time=last_byte;
    server backend1.example.com;
    server backend2.example.com;
}
```

- 服务器权重
nginx默认服务器权重为1，服务器权重配置如下：
```java
upstream backend {
    server backend1.example.com weight=5;
    server backend2.example.com;
}
```
例：此时有6个请求到达，那么有5个请求会分发到backend1，剩下一个分发到backend2.

- 备用的服务器
备用服务器在有其他服务器不可用情况下会启用，配置如下：
```java
upstream backend {
    server backend1.example.com;
    server backend2.example.com;
    server 192.0.0.1 backup;
}
```

- 服务器慢启动
服务器慢启动为了保护最近恢复的服务器，不会因为大量的连接请求而导致再次被故障。慢启动使用**0**作为最近恢复的服务器权重，随后再渐渐恢复到正常值。配置如下：
```java
upstream backend {
    server backend1.example.com slow_start=30s;
    server backend2.example.com;
    server 192.0.0.1 backup;
}
```
backend1服务器在启动后会在30s内，渐渐恢复到最大连接数的状态

**注意**：在一个upstream组中如果只有一个服务器，那么max_fails，fail_timeout和slow_start参数会失效

- 会话持久性
nginx定义用户请求session并把具有相同session的请求转发到相同的upstream服务器

    - Stickey cookie：nginx添加cookie到upstream组中对首次请求进行响应的服务器，客户端下次请求会直接路由到该服务器。配置如下：
    ```java
    upstream backend {
    server backend1.example.com;
    server backend2.example.com;
    sticky cookie srv_id expires=1h domain=.example.com path=/;
}
```
    - Sticky route:为第一次收到的请求客户端指定一个**路由**，所有子请求，带有路由标识的都会直接分发到该服务器，路由标识由cookie或请求url携带，配置如下：
    ```java
    upstream backend {
    server backend1.example.com route=a;
    server backend2.example.com route=b;
    sticky route $route_cookie $route_uri;
    }
    ```
    - Sticky learn:nginx通过检查请求和响应来查找会话，并从中匹配符合会话的服务器，会话标识通常置于HTTP cookie中，而**不存在于客户端**中。配置如下：
    ```java
    upstream backend {
   server backend1.example.com;
   server backend2.example.com;
   sticky learn
       create=$upstream_cookie_examplecookie
       lookup=$cookie_examplecookie
       zone=client_sessions:1m
       timeout=1h;
       sysnc;//如果有多个nginx实例使用该持久方式时且需要同步共享内存区域
    }
    ```
        上述例子中，必填参数**create**指定创建的会话标识符examplecookie，必填参数**lokup**指定如何查找会话标识符，必填参数**zone**标识携带该会话标识符的会话**共享的内存区域**，这种复杂的配置将coolie保存在服务器共享区域中，而不是客户端.

- 限制连接数量，配置如下:
    ```java
    upstream backend {
        server backend1.example.com max_conns=3;
        server backend2.example.com;
        queue 100 timeout=70;
    }
    ```
    如果max_conns达最大限制，可以设置queue来进一步处理（队列中最大存在的请求数，以及请求超时时间）
    
- nginx工作进程共享区域
如果一个upstream组**没有配置zone指令**，每一个工作进程都会拥有独立的一份**服务器组配置副本**和一个计数器（包括组中每个服务器当前**连接数**以及请求**分发失败次数**）。这样带来的问题是没法动态修改服务器组配置。每个请求仅到达一个工作进程，当该工作进程**无法将请求分发**时，**其他进程一无所知**，而其他工作进程仍可能向该服务发送请求。同样，在**低负载**情况下，如果使用least connections负载策略，每个进程都会以自己副本中连接数作为标准进行请求分发（有可能该服务器才响应一个请求）。zone指令对于活跃检查和动态配置是必填参数。
    - zone区域大小设置在不同使用模式下差异很大，取决于启用的功能（会话持久性，活跃检查，DNS解析）,在sticky_route的持久方式和单个活跃检查情况下，256KB的设置可保存消息如下：
        - 123个服务器（IP地址：端口对）
        - 88个服务器（主机名：端口对，主机名解析为**单个IP地址**）
        - 12个服务器（主机名：端口对，其中主机名解析为**多个IP地址**）

- DNS负载HTTP请求
通过在server指令下定义代理路由指向upstream组，nginx监听dns列表的变化并自动应用更新，配置如下：
    ```java
    http {
        resolver 10.0.0.1 valid=300s ipv6=off;// DNS服务器地址，以及重新解析频率，适用解析IP规则
        resolver_timeout 10s;
        server {
            location / {
                proxy_pass http://backend;
            }
        }
        upstream backend {
            zone backend 32k;
            least_conn;
            # ...
            server backend1.example.com resolve;
            server backend2.example.com resolve;
        }
    }
    ```

#### **TCP,UDP负载**
tcp的负载需nginx plus版本达到 release 5，UDP则要达到9

- 配置反向代理
和http负载一样，定义顶模块stream，然后在**stream{}**模块下用**server{}**定义虚拟服务器（监听ip，端口，TCP/UDP协议）;

    ```java
    stream {
        server {
            listen 12345;//listen 12345 udp;
            proxy_pass stream_backend;
            //proxy_pass backend.example.com:12346; 如果代理服务器有多个网络接口的时候，你可以选择使用特定ip地址
             proxy_bind  127.0.0.1:12345;
             proxy_buffer_size 16k;// 配置来自客户端和upstream连接的数据
             
        } 
    }
    ```

- 配置负载均衡
在**stream{}**模块下用**upstream{}**定义上游服务器组,注意服务器组中不需要定义协议，在上面**server{}**模块就已经指定

    ```java
    stream {
        upstream stream_backend {
            server backend1.example.com:12345;
            server backend2.example.com:12345;
            server backend3.example.com:12346;
            # ...
        }
    
        upstream dns_servers {
            server 192.168.136.130:53;
            server 192.168.136.131:53;
            # ...
        }
    
        # ...
    }
    ```
    - 负载策略
    和http负载配置一样，可以使用round robin,least connections,least time（唯一和HTTP配置区别：没有last_type inflight选项，多出connect选项：连接到上游服务器的时间），hash，random，option

------------------------------
- **即时配置**upstream group server
使用nginx plus **rest api**轻松动态重新配置上游服务器组。配置如下：

    ```java
    http {
        server {
            location /api {// 设置rest api根路径
                api   write=on;//设置**可写**，默认api只可读
                allow 127.0.0.1; // 限制访问ip
                deny  all; 
            }
        }
    }
    ```
    
    **建议**：在api write=on模式下，建议特殊路由限制patch，post和delete方法，配置如下：
    
    ```java
    http {
        server {
            location /api {
                limit_except GET {
                    auth_basic "NGINX Plus API";
                    auth_basic_user_file /path/to/passwd/file;
                }
                api   write=on;
                allow 127.0.0.1;
                deny  all;
            }
        }
    }
    ```

   通过**nginx plus rest api**所做更改仅仅存在于共享内存区域中，重新加载nginx plus配置文件后，更改将失效。要使动态配置持久化，1.将upstream 服务器从模块配置中移到存储服务器状态的特殊文件中，配置如下：

    ```java
    http {
        upstream appservers {
            zone appservers 64k;
//      state /var/lib/nginx/state/appservers.conf;
        }
    }
    ```

#### **HTTP health checks**

- 被动检查：通过在upstream模块中的server定义 **max_fails和fail_timeout**参数，来实现被动检查，在某个最大重试次数或最大不可用时间内，下线某服务器某段时间.
- 主动检查：通过向每台服务器发送特殊运行状况检查请求来验证运行状况。在**server{}**模块下，**location{}**模块添加**health_check**参数，默认情况下，nginx每5秒向组中服务器发送一个“/”，如果通信错误或超时，则状况检查为失败。服务器标记为不正常后，nginx不会再向其发送客户端请求，直到再次通过健康检查。配置如下:
    
    ```java
        server {
            location / {
                proxy_pass   http://backend;
                health_check port=8080  interval = 10  失败= 3  pass = 2 ; //配置8080端口进行运行状况检查，将两次检查延迟从5s设置为10s，设置3次失败检查标记不健康，设置连续两次通过检查，可标记为健康正常
                health_check uri=/some/path // 在upstream goup中server中添加该指定url后缀为检查url
            }
        }
    ```

- 自定义检查条件
    ```java
    http {
        match server_ok {
            status 200-399;// 状态code响应正常范围
            header Content-Type = text/html;// header响应限制
            body !~ "maintenance mode";// 消息体响应限制
        }
        
        server {
            location / {
                proxy_pass http://backend;
                health_check match=server_ok;
            }
        }
    }
    ```

#### **TCP/UDP health checks**
**tcp和udp和http健康检查一样**，有被动检查，主动检查，配置，参数基本差不多，在自定义**match中允许使用send和expect参数进行自定义校验**


#### **接收代理协议**?TODO

nginx应用代理协议可以通过代理服务器和负载均衡器接收客户端连接信息，从而设置特定语言为不同web站点，建立黑名单，简单日志以及统计功能。

- 配置nginx接受代理协议报头，配置如下：
    
    ```java
    http {
        server {
            listen 80   proxy_protocol;
            listen 443  ssl proxy_protocol;
            #...
        }
    }

    stream {
        server {
            listen 12345 proxy_protocol;
        }
    }
    ```
    
### **nginx文本缓存**
启用缓存后，nginx plus将响应保存在磁盘缓存中，并使用它们来响应客户端。

- 启用缓存
将**proxy_cache_path**指令配置在顶级模块中，配置如下：
    ```java
    http  {
        proxy_cache_path  / data / nginx / cache  keys_zone = one：10m ; // 配置缓存文本本地文件路径。2存储有关缓存项元数据的共享内存区名称和大小
    }
 
    server {
        proxy_cache mycache;
        location / {
            proxy_pass http://localhost:8000;
        }
    }
    ```
    
- nginx缓存涉及的进程
    特定创建两个进程为**缓存管理器**和**缓存加载器**，前者周期性检查缓存状态，假如缓存大小超过**proxy_cache_path**配置**max_size**,缓存管理器会移除最近使用最少的数据；后者只会运行一次，在nginx启动的时候一次性加载元数据到共享内存区域，正是因为一次性加载到内存可能会造成资源大量消耗而拖累nginx的响应，所以通常在**proxy_cache_path**指令中添加如下参数配置缓存的迭代加载：
    - loader_threshold：迭代持续时间，以毫秒为单位（默认为200）
    - loader_files：一次迭代期间加载的最大项目数（默认为100）
    - loader_sleeps：迭代之间的延迟，以毫秒为单位（默认为50）

- 指定要缓存的请求
nginx默认缓存对所有get和head首次请求的响应。通过匹配请求字符串作为请求的键
    - 请求key特征：
    ```java
    proxy_cache_key “$host $request_uri $cookie_user”;
    ```
    
    - 缓存响应相同key请求最小次数：
    ```java
    proxy_cache_min_uses  5 ;
    ```
    
    - 缓存其他HTTP请求方法：
    ```java
    proxy_cache_methods GET HEAD POST ;
    ```
    
- 限制或禁用缓存
more情况下，响应无限期保留在缓存中。当缓存超过最大配置缓存时才根据缓存驻留时间依次将其删除
    - 缓存驻留时间配置：
    ```java
    proxy_cache_valid 200 302 10m;// 200,302请求10分钟内有效时间 
    proxy_cache_valid 404 1m ;// 404响应1分钟为有效时间
    proxy_cache_valid any 5m;// 任意状态码 5分钟为有效时间
    ```
    
    - 不向客户端发送缓存响应的条件配置：
    ```java
    proxy_cache_bypass $cookie_nocache $arg_nocache $arg_comment ;
    ```
    
    - 根本不缓存响应的条件配置：
    ```java
    proxy_no_cache $http_pragma $http_authorization;
    ```
    
- 清除缓存
nginx提供从缓存中删除过期缓存文件，收到自定义HTTP报头的请求或HTTP的PURGE方法。配置如下：
    ```java
    http {
        proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=mycache:10m purger=on;
    // 1配置缓存本地路由 2配置缓存共享内存空间名称和大小3激活遍历清除开关
        map $request_method $purge_method {
            PURGE 1; // 创建purge method变量映射于request method变量
            default 0;
        }
    
        server {
            listen      80;
            server_name www.example.com;
    
            location / {
                proxy_pass        https://localhost:8002;
                proxy_cache       mycache;
                proxy_cache_purge $purge_method;// 配置缓存清除条件
            }
        }
    
        geo $purge_allowed {
           default         0;
           10.0.0.1        1;
           192.168.0.0/24  1;
        } // 配置允许清除请求的ip限制，1代表运行 0代表拒绝
    
        map $request_method $purge_method {
           PURGE   $purge_allowed;
           default 0;
        }
    }
    ```

- 切片缓存
初始化缓存有时会暂用大量时间，特别是大文件，客户端不得不等待整个文件下载到cache中。nginx支持使用**cache slice**模块对类似范围请求逐渐填充到cache中。每个范围请求选择该范围内特定切片，均在第一次加载到cache后，从cache中获取

    - 配置切片大小：
    ```java
        location / {
        slice  1m;// 太小会导致文件描述符打开过多，太大会导致延迟严重
    proxy_cache       cache;
    proxy_cache_key $uri $is_args $args $slice_range;
    proxy_set_header  Range $slice_range;
    proxy_cache_valid 200 206 1h;
    proxy_pass        http://localhost:8000;
    }
    ```

### nginx作为web服务器
较高级别上，nginx配置为web服务器只是定义它处理URL以及如何处理HTTP请求；较低级别，该配置定义一组虚拟服务器，这些服务器对特定域和IP地址请求进行处理。

- 定义虚拟服务器

    ```java
    http {
        server {
            listen 127.0.0.1:8080;// ip如果省略，则监听所有地址；端口如果省略，默认端口8000
        }
        server {
            listen 127.0.0.2:8210;// 可以配置多个监听端口
        }
    }
    ```
    
    如果多个server和请求的IP地址和端口相匹配，nginx则根据**请求报头字段server**匹配配置中的server；如果没有匹配的server，则nginx将请求分发到默认服务器（未指定则为nginx.conf文件中列出的第一个服务器）
- 定义location
一个location指令定义了如何解析请求url，并分发到静态文件还是代理服务器，多个location在重定向情况下可能会多次调用
    ```java
    server {
        location /images/ {
            root /data;
        }
    
        location / {
            proxy_pass http://www.example.com;
        }
        
        location /wrong/url {
            return 404  http://www.example.com/moved/here; // 定义返回状态码，和重定向地址
        }
        
        location /users/ {
            rewrite ^/users/(.*)$ /show?user=$1 break; // 根据正则匹配请求url，并请求重写路由
        }
    }
    
    location / {
    sub_filter 'href="http://127.0.0.1:8080/' 'href="https://$host/';
    sub_filter 'img src="http://127.0.0.1:8080/' 'img src="https://$host/'; // 重写或更改响应内容 
    sub_filter_once on;// sub_filter连续应用指令
}

    location /old/path.html {
        error_page 404 =301 http:/example.com/new/path.html; // 返回自定义错误页面，和错误码
    }
    ```
- 使用变量
在配置文件中定义变量，变量是在运行时计算的，变量以\，$开头

- 设置根目录，返回静态内容
    根据不同请求路由返回不同资源
    ```java
    server {
        root /www/data;
        
        location / {
        index index.$geo.html index.htm index.html; // 列出多个返回文件，顺序择优
        }
        
        location /images/ {
        autoindex on;//返回自动生成的目录列表
        }// 如果以 “/” 结尾,nginx会试图在该路径下找index文件，如果不存在则返回404
        
        location ~ \.(mp3|mp4) {
            root /www/media;
        }
          
        location /images/ {
        autoindextry_files  $ uri  /images/default.gif;//检查指定的文件或目录是否存在；NGINX会进行内部重定向，否则会返回指定的状态码
        }
             
    }
    ```
- web性能优化

    ```java 
    location /avi { 
        sendfile on;// 文件传输不再经过缓冲区，直接从一个文件描述符复制到另一个文件描述符
        sendfile_max_chunk 1m; // 限制单个sendfile调用传输的数据量
        tcp_nopush  on ; // nginx在获取到数据后立即在一个数据包中发送HTTP响应报头
        tcp_nodelay on ; // 无延迟发送包，禁用nagle算法
        keepalive_timeout  65 ; 
        
    }
    ```
nginx在建立连接后，将其放入侦听套接字队列中，在网站流量很大的时候，队列会急剧增长，导致连接断开和延迟增加，这时需要增加操作系统和nginx配置排队最大连接数

    ```java
    linux增加连接数
    // 显示监听队列
    netstat -Lan
    // 调整最大连接数
    sudo sysctl -w net.core.somaxconn=4096
    或 在/etc/sysctl.conf文件中添加配置项：net.core.somaxconn = 4096
    
    nginx调整
    server {
        listen 80 backlog=4096;
    }
    ```
- 反向代理

    ```java
    location /some/path/ {
proxy_set_header Host $host; // 修改/传递报头
proxy_set_header X-Real-IP $remote_addr;
proxy_pass http://www.example.com/link/; // 如果代理服务器地址以“/”结尾，则请求url会自动截取后面不匹配字符串拼接到代理请求地址后面
proxy_buffers 16 4k;// 控制规模和分配请求缓冲区数目
proxy_buffer_size 2k;// 来自代理服务器响应第一部分存储的单独缓冲区
    }
    ```
    - 非HTTP服务器代理指令
        - fastcgi_pass  
        - uwsgi_pass 
        - scgi_pass 
        - memcached_pass
    - 一般情况下，nginx缓存来自代理服务器的响应，响应存储在内部缓冲区中，直到接收到**整个响应**后才发送给客户端。这样有助于**优化慢速客户端性能**，避免由于nginx同步传递到客户端造成的**代理服务器的时间浪费**。启用缓冲后，nginx运行**代理服务器快速处理响应**，nginx将**响应存储时间和客户端下载响应所需时间一样长**。
    - 选择特定代理服务器
    如果代理服务器有多个网络接口，需要选择特定源IP地址连接到相应代理服务器时，配置如下：
    ```java
    location /app1/ {
    proxy_bind 127.0.0.1;
    proxy_pass http://example.com/app1/;
    }
    ```
- 解压缩

    ```java
    server {
    gzip on; // 开启压缩
    gzip_types text/plain application/xml;//默认只压缩MIME type text/html格式
    gzip_proxied    no-cache no-store private expired auth;// 默认情况下，NGINX不压缩对代理请求的响应（来自代理服务器的请求
    gzip_min_length 1000;// 最短压缩响应长度
    gunzip on;// 开启解压
  
    location / {
    gzip_static on;// 将文件的压缩版本（而不是常规文件）发送到客户端,如果该文件不存在，或者客户端不支持gzip，则NGINX发送该文件的未压缩版本。
    }
    }
    ```
    
### **nginx高可用支持** todo
