---
layout: post
title: 'Kafka 入门与实践'
subtitle: 'Kafka 入门与实践'
date: 2019-07-15
categories: 中间件
author: yates
cover: 'www.baidu.com'
tags: 中间件
---

## 前言 Kafka是一个高吞吐量，分布式，轻量级，可分区和具有赋值备份，开源的的发布-订阅消息系统。


### 基本概念

**主题**
一组消息抽象归纳为一个主题，一个主题就是对消息的一个分类。生产者将消息发送到特定主题，消费者订阅或主题的某些分区进行消费

**消息**
Kafka通信的基本单位，由固定长度的消息头和可变长度的消息体构成

**分区和副本**
每个主题被分为一个或多个分区。每个分区由消息组成，是一个有序队列。物理层面，每个分区对应一个文件夹，每个分区又有多个副本分布在集群不同代理上，副本抽象为一个日志对象，分区是Kafka保证消息被顺序消费以及对消息进行负载均衡的基础
不同分区的消息有序性不能得到保证。kafka对于已被消费的消息处理策略有两种：基于消息已存储的时间长度；基于分区大小

**Leader副本和Follower副本**
为了保证一个分区的多个副本之间数据的一致性，kafka会选择该分区一个副本作为leader副本，其他为follower副本。只有leader副本才负责处理客户端读/写请求。在没有leader副本的情况下所有副本都会继续读写请求，但是这样会很难保证副本之间数据的一致性。

**偏移量**
发布到分区的消息会被直接追加到日志文件尾部，每条消息在日志文件中位置都会对应一个按序递增的偏移量。

**日志段**
日志被划分为多个日志段，一个日志段对应磁盘上一个具体日志文件和两个索引文件（消息偏移量索引文件和消时间戳索引文件）

**代理**
kafka集群由一个或多个kafka实例构成，每一个实例称为代理，一台服务器配置一个或多个代理。每个代理在集群中使用一个非负整数作为唯一标识id，

**生产者**
向kafka代理发送消息的客户端

**消费者和消费组**
kafka消费者以拉的方式处理消息，每一个消费者属于一个特定消费组，每个消费者也有一个全局唯一的id。同一个主题的消息只能被同一个消费组下某一个消费者消费，不同消费组的消费者可同时消费该消息。
实现消息广播只需指定各消费者均属于不同消费组，消息单播则只需让各消费者属于同一个消息组

**ISR**
kafka在zk中动态维护一个ISR用来保存同步的副本列表，该列表中保存与Leader副本保持消息同步的所有副本对应代理节点id。在fllower失效的情况下，该副本节点会从ISR列表中移除

### 特性

**持久化**
kafka依赖于文件系统存储和缓存消息，因为kafka的写入/读取时线性执行的，所以在设计上kafka采用的是时间复杂度为O(1)的磁盘结构,而不是基于JVM的Java对象持久化，避免了频繁的垃圾回收。避免了使用B树等结构在大数据量情况下性能的现象下降

**高吞吐量**
除了写入顺序写入磁盘，kafka在数据写入和数据同步采用零拷贝技术，采用sendFile()函数调用（直接在两个文件描述符之间传递数据，不通过用户内存空间，避免了内核缓冲区和用户缓冲区之间数据拷贝）。kafka还支持数据压缩和批量发送。

**扩展性**
利用zk对集群进行管理，以达到负载均衡和数据复制的目的

**多客户端支持**
支持java，scale，c，pythong，go，node等语言客户端的接入支持

**安全机制**
SSL,通信数据加密，认证服务

**数据备份**
主题指定副本数，数据持久化备份

**轻量级**
代理不记录消息是否被消费，消费偏移量管理交由消费或组协调器维护

**数据压缩**
把多条消息放到一起组成MessageSet,然后把MessageSet放到一条消息里面


## 部署
安装jdk环境
安装 部署 : zookeper  配置zoo.cfg下  {dataDir}{dataLogDir}{clientPort}等配置 
启动: sh zkServer.sh start
安装 部署 : kafka：配置config/server.properties 下  {broker.id}{log.dirs}{zookeeper.connect}等配置
启动：sh kafka-server-start.sh -daemon ../config/server.properties
安装 部署 kafka manager
1 github下载源码  
2 到源码目录进行编译 ./sbt clean dist
3 编译成功后会给一个zip压缩包的目录，到目录下获取生成的压缩文件kafka-manager-*.zip文件
4 将压缩文件解压到指定位置 usr/local/software/kafka-manager目录下
5 修改安装目录下conf目录，打开application.conf文件 修改kafka-manger.zkhosts="kafka-manager-zookeeper:2181"配置项为实际zookeper的地址
6 启动  nohup ./kafka-manager -Dconfig.file=../conf/application.conf &
7 访问 serverIp:9000

8 关闭kafka-manager:通过杀死进程的方式，同时删除RUNNING_PID文件


## 核心组件

### 延迟组件

**delayedOperation**
delayedOperation是一个基于事件启动有失效时间的timerTadk。实现了runnable接口，每个task维护一个timetaskentry对象，timetaskentry对象添加到TimerTaskList（一个双向环形链表）

## kafka流程

kafkaserver.startup()启动并初始化组件，kafkascheduler，logManager，sockeserver，replicamanger，kafkacontroller，groupcoordinator，dynamicconfigmanager，kafkahealthchecker
kafkaserver实例化时会在log.dir指定目录下创建一个meta.properties文件，该文件记录当前kafka版本对应的一个版本version字段，一个代理broker.id字段。也就是说我们在不改变代理对应log.dir配置而修改改立brokerId时，不仅server.property需要修改，该处也需要修改



